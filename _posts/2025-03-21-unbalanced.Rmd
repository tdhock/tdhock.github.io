---
layout: post
title: Creating imbalanced data benchmarks
description: Tutorial with MNIST
---

```{r Ropts, echo=FALSE, results='hide'}
repo.dir <- normalizePath("..")
post.id <- "2025-03-21-unbalanced"
fig.path <- paste0(file.path(repo.dir, "assets", "img", post.id), "/")
dir.create(fig.path, showWarnings = FALSE, recursive = TRUE)
knitr::opts_chunk$set(
  dpi=100,
  fig.path=fig.path,
  fig.width=10, ## TODO python figures wider? look at prev issue.
  fig.process=function(path)sub(repo.dir, "", path, fixed=TRUE),
  fig.height=4)
in_render <- !is.null(knitr::opts_knit$get('rmarkdown.pandoc.to'))
in_knit <- isTRUE(getOption('knitr.in.progress'))
options(width=120)
if(FALSE){
  knitr::knit(paste0(post.id, ".Rmd"))
}
```

The goal of this post is to show how to create unbalanced classification data
sets for use with our recently proposed [SOAK
algorithm](https://arxiv.org/abs/2410.08643), which will be able to
tell us if we can train on imbalanced data, and get accurate
predictions on balanced data (and vice versa).

## Read and order MNIST data

We begin by reading the MNIST data,

```{r}
library(data.table)
MNIST_dt <- fread("~/projects/cv-same-other-paper/data_Classif/MNIST.csv")
data.table(
  name=names(MNIST_dt),
  first_row=unlist(MNIST_dt[1]),
  last_row=unlist(MNIST_dt[.N]))
```

We see that these MNIST data have a `predefined.set` column, which we
will ignore (use all data from train and test). The class distribution
is as follows:

```{r}
(multi_counts <- MNIST_dt[, .(
  count=.N,
  prop=.N/nrow(MNIST_dt)
), by=y][order(-prop)])
```

We see in the table above that there are about an equal amount of data
for each class, from 9% to about 11%.  We would like to preserve these
proportions when we take subsamples of the data.  To do that, we first
take a random order of the data (in case the original file had some
special structure), and then we assign a new proportional ordering
based on the label value.

```{r}
my.seed <- 1
set.seed(my.seed)
rand_ord <- MNIST_dt[, sample(.N)]
prop_ord <- data.table(y=MNIST_dt$y[rand_ord])[
, prop_y := seq(0,1,l=.N), by=y
][, order(prop_y)]
ord_list <- list(
  random=rand_ord,
  proportional=rand_ord[prop_ord])
ord_prop_dt_list <- list()
for(ord_name in names(ord_list)){
  ord_vec <- ord_list[[ord_name]]
  y_ord <- MNIST_dt$y[ord_vec]
  for(prop_data in c(0.01, 0.1, 1)){
    N <- nrow(MNIST_dt)*prop_data
    N_props <- data.table(y=y_ord[1:N])[, .(
      count=.N,
      prop_y=.N/N
    ), by=y][order(-prop_y)]
    ord_prop_dt_list[[paste(ord_name, prop_data)]] <- data.table(
      ord_name, prop_data, N_props)
  }
}
ord_prop_dt <- rbindlist(ord_prop_dt_list)
dcast(ord_prop_dt, ord_name + prop_data ~ y, value.var="prop_y")
```

The output above shows that the proportional ordering is much more
stable than the random ordering, which has lots of variations in each
column, between the different rows (values of prop_data).

## Converting to binary

To convert the data to a binary problem, we can create a new column
that indicates if the `y` label is odd=1 or even=0 (this will be used as
the label in supervised binary classification).

```{r}
(binary_counts <- MNIST_dt[
, odd := y %% 2
][, .(
  count=.N,
  prop=.N/nrow(MNIST_dt)
), by=odd][order(-prop)])
```

Above we see that each of the two classes is about equally prevalent.

## Creating class imbalance

We will create different versions of MNIST, each version having two subsets:

* one which is balanced: 50% positive labels (odd=1), 50% negative labels (odd=0).
* one which is unbalanced: 50% positive labels (odd=1), and a smaller
  proportion of negative labels (from 10% to 0.1%).

To do that, we use the following code to compute the number of samples
we would need:

```{r}
larger_N <- binary_counts$count[1]/2
target_prop <- c(0.5, 0.1, 0.05, 0.01, 0.005, 0.001)
(smaller_dt <- data.table(
  target_prop,
  count=as.integer(target_prop*larger_N/(1-target_prop))
)[
, prop := count/(count+larger_N)
][])
```

Above we see 

* `target_prop`, the desired proportion of negative labels in the unbalanced subset,
* `count`, the number of negative labels in the unbalanced subset which gives the best proportion closest to the target,
* `prop`, the proportion of negative labels in the unbalanced subset, that corresponds to the actual count.

It is clear from the table above that the empirical proportions are
consistent with the target proportions. To create the different unbalanced data
sets, we first create a table with one row for each target proportion in the unbalanced subset:

```{r}
(unb_small_dt <- data.table(
  subset="unbalanced",
  binary_counts[2,.(odd)],
  smaller_dt[-1]))
```

The table above has one row for each unbalanced variant (from 10% to
0.1%) that we will create based on the original MNIST data. Below we
use a for loop over the rows of this table, to assign rows to each
subset of each unbalanced variant (each corresponding to a column of
`subset_mat`).

```{r}
subset_mat <- matrix(
  NA, nrow(MNIST_dt), nrow(unb_small_dt),
  dimnames=list(
    NULL,
    target_prop=paste0(
      "seed",
      my.seed,
      "_prop",
      unb_small_dt$target_prop)))
emp_y_list <- list()
emp_props_list <- list()
MNIST_ord <- MNIST_dt[, .(odd, .I)][ord_list$proportional]
for(unb_i in 1:nrow(unb_small_dt)){
  unb_row <- unb_small_dt[unb_i]
  unb_count_dt <- rbind(
    data.table(subset="balanced", binary_counts[,.(odd)], smaller_dt[1]),
    data.table(subset="unbalanced", binary_counts[1,.(odd)], smaller_dt[1]),
    unb_row)
  MNIST_ord[, subset := NA_character_]
  for(o in c(1,0)){
    o_dt <- unb_count_dt[odd==o]
    sub_vals <- o_dt[, rep(subset, count)]
    o_idx <- which(MNIST_ord$odd==o)
    some_idx <- o_idx[1:length(sub_vals)]
    MNIST_ord[some_idx, subset := sub_vals]
  }
  subset_mat[MNIST_ord$I, unb_i] <- MNIST_ord$subset
  ## Check to make unbalanced is a subset of the previous larger one.
  if(unb_i>1)stopifnot(all(which(
    subset_mat[,unb_i]=="unbalanced"
  ) %in% which(
    subset_mat[,unb_i-1]=="unbalanced"
  )))
  ## Check to make sure balanced is the same as previous.
  if(unb_i>1)stopifnot(identical(
    which(subset_mat[,unb_i]=="balanced"),
    which(subset_mat[,unb_i-1]=="balanced")
  ))
  (unb_MNIST <- data.table(
    target_prop=unb_row$target_prop,
    subset=subset_mat[,unb_i],
    odd=MNIST_dt$odd,
    y=MNIST_dt$y)[, idx := .I][!is.na(subset)])
  emp_y_list[[unb_i]] <- unb_MNIST[, .(
    count=.N
  ), by=.(target_prop,subset,y)]
  emp_props_list[[unb_i]] <- unb_MNIST[, .(
    count=.N,
    first=idx[1], 
    last=idx[.N]
  ), by=.(target_prop,subset,odd)
  ][
  , prop_in_subset := count/sum(count)
  , by=subset
  ][]
}
emp_y <- rbindlist(emp_y_list)
(emp_props <- rbindlist(emp_props_list))
```

The table above can be used to verify that the subset assignments are
consistent with the target label proportions. It has one row for each
unique combination of target proportion, subset, and label (odd). For
each value of target proportion, 

* each balanced subset has the same data, as can be seen by examining
  columns count, first, and last. The `prop_in_subset` column shows
  that the class labels are balanced (half of each).
* each unbalanced subset has the same first index values, but
  different last index values. The smaller
  unbalanced subsets are strict subsets of the larger unbalanced
  subsets (for example the 5% unbalanced subset is
  also a part of the 10% unbalanced subset).
  
To verify that the underlying multi-class proportion is consistent in
the down-sampled subsets, we use the code below:

```{r}
dcast(emp_y, subset + target_prop ~ y, value.var="count")
```

The table above has one row per subset, and one column per class
(there are ten original classes in MNIST, 0-9). It is clear that 

* the balanced subset always has the same number of data, for each
  value of target proportion.
* the unbalanced subset number of data depends on the class label:
  * for odd labels, there are always the same number of samples.
  * for even labels, the number of samples depends on the target
    proportion, and is uniform across classes (0 about the same number
    as 2 for example).

## Write the subset columns to a new CSV file

Finally, we create new columns for each subset.

```{r}
fwrite(subset_mat, "2025-03-21-unbalanced.csv")
system("head 2025-03-21-unbalanced.csv")
```

## Conclusions

This tutorial showed how to create unbalanced data sets, and check
that they obey certain constraints:

* balanced subsets are the same for different imbalance ratios,
* imbalanced subsets are nested (smaller one is strict subset of larger one).

## Session info

```{r}
sessionInfo()
```
