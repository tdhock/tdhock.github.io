---
layout: post
title: Cross-validation with neural networks
description: Demonstration of mlr3torch + mlr3resampling
---

```{r Ropts, echo=FALSE, results='hide'}
repo.dir <- normalizePath("..")
post.id <- "2024-10-30-mlr3torch"
fig.path <- paste0(file.path(repo.dir, "assets", "img", post.id), "/")
dir.create(fig.path, showWarnings = FALSE, recursive = TRUE)
knitr::opts_chunk$set(
  dpi=100,
  fig.path=fig.path,
  fig.width=10, ## TODO python figures wider? look at prev issue.
  fig.process=function(path)sub(repo.dir, "", path, fixed=TRUE),
  fig.height=4)
conda.env <- "2023-08-deep-learning"
conda.env <- "torch-aum"
RETICULATE_PYTHON <- sprintf(if(.Platform$OS.type=="unix")
  ##"/home/tdhock/.local/share/r-miniconda/envs/%s/bin/python"
  "/home/tdhock/miniconda3/envs/%s/bin/python"
  else "~/AppData/Local/Miniconda3/envs/%s/python.exe", conda.env)
Sys.setenv(RETICULATE_PYTHON=RETICULATE_PYTHON)
##reticulate::use_condaenv(dirname(RETICULATE_PYTHON), required=TRUE)
in_render <- !is.null(knitr::opts_knit$get('rmarkdown.pandoc.to'))
in_knit <- isTRUE(getOption('knitr.in.progress'))
options(width=120)
if(FALSE){
  knitr::knit(paste0(post.id, ".Rmd"))
}
```

The goal of this post is to show how to use the mlr3torch package in R
with AUM (Area Under Min of False Positive and False Negative rates,
our newly Proposed surrogate loss for ROC curve optimization), in
combination with the new cross-validation methods we proposed in our
[SOAK paper](https://arxiv.org/abs/2410.08643).

## Introduction 

Last Friday I gave a talk at [MILA](https://mila.quebec/en), [Two new
algorithms for scientific applications of machine
learning](https://github.com/tdhock/two-new-algos-sci-ml/tree/main?tab=readme-ov-file#title-abstract-slides).
The first algorithm that I discussed is [SOAK: Same/Other/All K-fold
cross-validation for estimating similarity of patterns in data
subsets](https://arxiv.org/abs/2410.08643). One simple
demonstration of the algorithm involves three image classification benchmark data sets. Code below adapted from [my github repo](https://github.com/tdhock/cv-same-other-paper/blob/main/data_Classif_MNIST_other.R):

```{r}
other.name.vec <- c("EMNIST", "FashionMNIST")
data.name.vec <- c(other.name.vec, "MNIST")
```

First we download those data sets.

```{r}
prefix <- "https://rcdata.nau.edu/genomic-ml/cv-same-other-paper/data_Classif/"
data_Classif <- "~/projects/cv-same-other-paper/data_Classif"
options(timeout = 600)#seconds
for(data.name in data.name.vec){
  data.csv <- paste0(data.name, ".csv")
  local.csv <- file.path(data_Classif, data.csv)
  if(!file.exists(local.csv)){
    remote.csv <- paste0(prefix, data.csv)
    download.file(remote.csv, local.csv)
  }
}
```

Next we read these data into R (only the first few rows, for
demonstration purposes).

```{r}
data.list <- list()
library(data.table)
for(data.name in data.name.vec){
  data.csv <- paste0(data.name, ".csv")
  local.csv <- file.path(data_Classif, data.csv)
  data.list[[data.name]] <- fread(local.csv, nrows = 1000)
}
```

Next, we plot an example of each class. To do that in the ggplot
framework, we need to create a data frame with one row per pixel to
display, as in the code below.

```{r}
n.pixels <- 28
pseq <- 1:n.pixels
(one.ex.dt <- data.table(Data=data.name.vec)[, {
  data.list[[Data]][, data.table(
    intensity=unlist(.SD[1]),
    pixel_j=rep(pseq, n.pixels),
    pixel_i=rep(pseq, each=n.pixels)
  ), by=y, .SDcols=patterns("[0-9]")]
}, by=Data])
```

We can visualize the images by using the ggplot code below.

```{r plot-images}
library(ggplot2)
ggplot()+
  theme_bw()+
  theme(panel.spacing=grid::unit(0,"lines"))+
  scale_y_reverse()+
  scale_fill_gradient(low="white",high="black")+
  geom_tile(aes(
    pixel_j, pixel_i, fill=intensity),
    data=one.ex.dt)+
  facet_grid(Data ~ y)+
  coord_equal()
```

We see in the image above that the EMNIST digits are transposed
(rotated 90 degrees and flipped) with respect to the MNIST digits.
Correction below.

```{r plot-EMNIST-rot}
data.list$EMNIST_rot <- data.list$EMNIST[,c(
  1,2,as.integer(matrix(seq(1,n.pixels^2),n.pixels,n.pixels,byrow=TRUE))+2
),with=FALSE]
(one.ex.dt <- data.table(Data=names(data.list))[, {
  data.list[[Data]][, data.table(
    intensity=unlist(.SD[1]),
    pixel_j=rep(pseq, n.pixels),
    pixel_i=rep(pseq, each=n.pixels)
  ), by=y, .SDcols=patterns("[0-9]")]
}, by=Data])
ggplot()+
  theme_bw()+
  theme(panel.spacing=grid::unit(0,"lines"))+
  scale_y_reverse()+
  scale_fill_gradient(low="white",high="black")+
  geom_tile(aes(
    pixel_j, pixel_i, fill=intensity),
    data=one.ex.dt)+
  facet_grid(Data ~ y)+
  coord_equal()
```

Above we see the `EMNIST_rot` data in the same orientation as the `MNIST` data.

## Convert data to torch tensors

In my [Res Baz 2023
tutorial](https://rcdata.nau.edu/genomic-ml/2023-res-baz-az/2023-04-19-deep-learning.html),
I explained how to use torch in R. The first step is to convert the
data from R to a torch tensor.

```{r}
ex.dt <- data.list$FashionMNIST
ex.X.mat <- as.matrix(ex.dt[,-(1:2),with=FALSE])
ex.X.array <- array(ex.X.mat, c(nrow(ex.dt), 1, n.pixels, n.pixels))
ex.X.tensor <- torch::torch_tensor(ex.X.array)
ex.X.tensor$shape
(ex.y.tensor <- torch::torch_tensor(ex.dt$y+1L, torch::torch_long()))
```

The data above represents a set of images in torch. Note that there are
four dimensions used to represent the images:

* the first dimension represents the different images (`nrow(ex.dt)` elements in
  the example above, one for each image).
* the second dimension represents the color channels (1 in the example
  above, for grayscale images).
* the third and fourth dimensions represent the height and width of
  the image in pixels (28 in the example above).

## torch linear model

A linear model is defined in the code below.

```{r}
torch::torch_manual_seed(1)
n.features <- ncol(ex.X.mat)
n.classes <- 10
seq_linear_model <- torch::nn_sequential(
  torch::nn_flatten(),
  torch::nn_linear(n.features, n.classes))
two.X.tensor <- ex.X.tensor[1:2,,,]
(seq_linear_model_pred <- seq_linear_model(two.X.tensor))
```

The prediction of the linear model is a tensor with two rows and ten
columns (one output column for each class). To do learning we need to
call backward on the result of a loss function, as in the code below.

```{r}
seq_linear_model$parameters[[2]]$grad
celoss <- torch::nn_cross_entropy_loss()
two.y.tensor <- ex.y.tensor[1:2]
(seq_linear_model_loss <- celoss(seq_linear_model_pred, two.y.tensor))
seq_linear_model_loss$backward()
seq_linear_model$parameters[[2]]$grad
```

Note in the output above that `grad` is undefined at first, and then
defined after having called `backward()`.

## Learning with linear model

For learning we should first divide train data into subtrain and validation.

```{r}
set_names <- c("validation", "subtrain")
set_vec <- rep(set_names, l=nrow(ex.dt))
table(set_vec, torch::as_array(ex.y.tensor))
```

The table above shows that there are about an equal number of observations in each class and set.
Then we can use a gradient descent learning for loop,

```{r plot-torch-linear}
n.epochs <- 1000
step_size <- 0.1
optimizer <- torch::optim_sgd(seq_linear_model$parameters, lr=step_size)
loss_dt_list <- list()
for(epoch in 1:n.epochs){
  set_loss_list <- list()
  for(set_name in set_names){
    is_set <- set_vec==set_name
    set_pred <- seq_linear_model(ex.X.tensor[is_set,,,])
    set_y <- ex.y.tensor[is_set]
    is_error <- set_y != set_pred$argmax(dim=2)
    N_errors <- torch::as_array(is_error$sum())
    set_loss_list[[set_name]] <- celoss(set_pred, set_y)
    loss_dt_list[[paste(epoch, set_name)]] <- data.table(
      epoch, set_name=factor(set_name, set_names),
      variable=c("error_percent","loss"),
      value=c(
        100*N_errors/length(is_error),
        torch::as_array(set_loss_list[[set_name]])))
  }
  optimizer$zero_grad()
  set_loss_list$subtrain$backward()
  optimizer$step()
}
(loss_dt <- rbindlist(loss_dt_list))

(min_dt <- loss_dt[, .SD[which.min(value)], by=.(variable,set_name)])
ggplot()+
  geom_line(aes(
    epoch, value, color=set_name),
    data=loss_dt)+
  geom_point(aes(
    epoch, value, color=set_name),
    shape=21,
    fill="white",
    data=min_dt)+
  facet_grid(variable ~ ., scales="free")
```

The results above show that the best validation error is about 16%,
around 300 epochs.

## Comparison with glmnet

Another implementation of linear models is given in the glmnet
package, which has automatic regularization parameter tuning via the
`cv.glmnet` function, but below we use the `glmnet` function for a
more direct comparison with what we did using torch above.

```{r plot-glmnet}
subtrain.X <- ex.X.mat[set_vec=="subtrain",]
ex.y.fac <- factor(torch::as_array(ex.y.tensor))
subtrain.y <- ex.y.fac[set_vec=="subtrain"]
fit_glmnet <- glmnet::glmnet(subtrain.X, subtrain.y, family="multinomial")
pred_glmnet <- predict(fit_glmnet, ex.X.mat, type="class")
err_glmnet_mat <- pred_glmnet != ex.y.fac

err_glmnet_dt_list <- list()
for(set_name in set_names){
  err_glmnet_dt_list[[set_name]] <- data.table(
    set_name=factor(set_name, set_names),
    penalty=fit_glmnet$lambda,
    complexity=-log10(fit_glmnet$lambda),
    error_percent=colMeans(err_glmnet_mat[set_vec==set_name,])*100)
}
err_glmnet_dt <- rbindlist(err_glmnet_dt_list)
(min_glmnet_dt <- err_glmnet_dt[, .SD[which.min(error_percent)], by=set_name])
ggplot()+
  theme_bw()+
  geom_line(aes(
    complexity, error_percent, color=set_name),
    data=err_glmnet_dt)+
  geom_point(aes(
    complexity, error_percent, color=set_name),
    data=min_glmnet_dt,
    shape=21,
    fill="white")+
  scale_x_log10()
```

The figure above shows that the min validation error is about 23%,
slightly larger than the torch linear model.

## torch convolutional neural network

Below we define a convolutional network.

```{r}
torch::torch_manual_seed(1)
out_channels <- 20
conv_kernel_size <- 3
pool_kernel_size <- 2
seq2flat <- torch::nn_sequential(
  torch::nn_conv2d(
    in_channels = 1,
    out_channels = out_channels,
    kernel_size = conv_kernel_size),
  torch::nn_relu(),
  torch::nn_max_pool2d(
    kernel_size = pool_kernel_size),
  torch::nn_flatten())
two.flat <- seq2flat(two.X.tensor)
n.flat <- ncol(two.flat)
n.hidden.units <- 20
seq_conv_model <- torch::nn_sequential(
  seq2flat,
  torch::nn_linear(n.flat, n.hidden.units),
  torch::nn_relu(),
  torch::nn_linear(n.hidden.units, n.classes))
(seq_conv_model_pred <- seq_conv_model(two.X.tensor))
seq_conv_model$parameters[[2]]$grad
(seq_conv_model_loss = celoss(seq_conv_model_pred, two.y.tensor))
seq_conv_model_loss$backward()
seq_conv_model$parameters[[2]]$grad
```

The output above indicates a gradient has been computed for the
convolutional network. Below we do the learning loop,

```{r}
optimizer <- torch::optim_sgd(seq_conv_model$parameters, lr=step_size)
conv_loss_dt_list <- list()
for(epoch in 1:n.epochs){
  cat(sprintf("%4d / %4d epochs\n", epoch, n.epochs))
  set_loss_list <- list()
  for(set_name in set_names){
    is_set <- set_vec==set_name
    set_pred <- seq_conv_model(ex.X.tensor[is_set,,,])
    set_y <- ex.y.tensor[is_set]
    is_error <- set_y != set_pred$argmax(dim=2)
    if(set_name=="subtrain"){
      batch_size <- length(ex.y.tensor)
    }
    N_errors <- torch::as_array(is_error$sum())
    set_loss_list[[set_name]] <- celoss(set_pred, set_y)
    conv_loss_dt_list[[paste(epoch, set_name)]] <- data.table(
      epoch, set_name=factor(set_name, set_names),
      variable=c("error_percent","loss"),
      value=c(
        100*N_errors/length(is_error),
        torch::as_array(set_loss_list[[set_name]])))
  }
  optimizer$zero_grad()
  set_loss_list$subtrain$backward()
  optimizer$step()
}
(conv_loss_dt <- rbindlist(conv_loss_dt_list))
(conv_min_dt <- conv_loss_dt[, .SD[which.min(value)], by=.(variable,set_name)])
ggplot()+
  geom_line(aes(
    epoch, value, color=set_name),
    data=conv_loss_dt)+
  geom_point(aes(
    epoch, value, color=set_name),
    shape=21,
    fill="white",
    data=conv_min_dt)+
  facet_grid(variable ~ ., scales="free")
```

## mlr3torch

The mlr3torch package provides an alternative way of defining torch
models, using the
[pipeops](https://mlr3torch.mlr-org.com/articles/pipeop_torch.html)
framework. The advantage of this approach is that each model can be
converted to a `Learner` object, which can be run alongside other
non-torch learners (such as glmnet), on lots of different data sets
and train/test splits (in parallel using mlr3batchmark). They can be
even run using my newly proposed SOAK algorithm (Same/Other/All K-fold
cross-validation), which can be implemented using the code below.

```{r}
soak <- mlr3resampling::ResamplingSameOtherSizesCV$new()
```

Note that it is important to run the line of code above, before
creating the tasks using the code below, because `mlr3resampling`
package needs to be loaded in order to avoid an error (`subset` is not
a valid column role).
The code below converts each data set of interest to a Task.

```{r}
task.list <- list()
for(other.name in c("EMNIST_rot","FashionMNIST")){
  ipair.dt.list <- list()
  for(Data in c(other.name,"MNIST")){
    one.dt <- data.list[[Data]][,-1][, y := factor(y)][]
    setnames(one.dt, c("y", paste0("X", names(one.dt)[-1])))
    ipair.dt.list[[Data]] <- data.table(Data, one.dt)
  }
  ipair.dt <- rbindlist(ipair.dt.list, use.names=FALSE)
  ipair.name <- paste0("MNIST_",other.name)
  itask <- mlr3::TaskClassif$new(
    ipair.name, ipair.dt, target="y")
  itask$col_roles$stratum <- "y"
  itask$col_roles$subset <- "Data"
  itask$col_roles$feature <- paste0("X",seq(0,n.pixels^2-1))
  task.list[[ipair.name]] <- itask
}
task.list
```

Note that the code above produces a list of two tasks, each of which
has two subsets.

* `MNIST_FashionMNIST` has two subsets: half MNIST images (digits),
  half FashionMNIST images (clothing). It should not be possible to
  get good accuracy when training on MNIST and predicting on
  FashionMNIST.
* `MNIST_EMNIST_rot` has two subsets: half MNIST images (digits), half
  EMNIST images (also digits), so it may be possible to get good
  prediction, even though the two data sets have different
  pre-processing methods (slightly different position / size of digit
  images).
  
### Define linear model in mlr3torch

I understand from `?mlr3torch::PipeOpTorchIngressNumeric` that we need
`po("torch_ingress_num")` to convert regular R features to torch
tensors. And we need `nn_head` pipeop at the end of the network, which
automatically determines the right number of output units, based on
the loss function.

```{r}
po_list_linear_ce <- list(
  mlr3pipelines::po(
    "select",
    selector = mlr3pipelines::selector_type(c("numeric", "integer"))),
  mlr3torch::PipeOpTorchIngressNumeric$new(),
  mlr3pipelines::po("nn_head"),
  mlr3pipelines::po(
    "torch_loss",
    mlr3torch::t_loss("cross_entropy")),
  mlr3pipelines::po(
    "torch_optimizer",
    mlr3torch::t_opt("sgd", lr=step_size)),
  mlr3pipelines::po(
    "torch_model_classif",
    batch_size = batch_size,
    epochs = n.epochs))
graph_linear_ce <- Reduce(mlr3pipelines::concat_graphs, po_list_linear_ce)
(glearner_linear_ce <- mlr3::as_learner(graph_linear_ce))
glearner_linear_ce$base_learner()
```

To configure the learner object above, we use the code below, adapted
from
https://mlr-org.github.io/mlr3torch-course/notebooks/6-mlr3torch.html

```{r}
measure_list <- mlr3::msrs(c("classif.logloss", "classif.ce"))
glearner_linear_ce$configure(
  validate = 0.5,
  callbacks = mlr3torch::t_clbk("history"),
  predict_type = "prob",
  measures_valid = measure_list,
  measures_train = measure_list)
```

The code below does the learning

```{r}
glearner_linear_ce$train(task.list$MNIST_FashionMNIST)
bl_linear_ce$callbacks
```

### Define neural network in mlr3torch

I understand from `?mlr3torch::PipeOpTorchIngressNumeric` that we need
`po("torch_ingress_num")` to convert regular R features to torch
tensors. And we need `nn_head` pipeop at the end of the network,
before `torch_loss`?

```{r}
po_list <- list(
  mlr3pipelines::po(
    "select",
    selector = mlr3pipelines::selector_type(c("numeric", "integer"))),
  mlr3torch::PipeOpTorchIngressNumeric$new(),
  mlr3pipelines::po(
    "nn_reshape",
    shape=c(-1,1,n.pixels,n.pixels)),
  mlr3pipelines::po(
    "nn_conv2d_1",
    out_channels = out_channels,
    kernel_size = conv_kernel_size),
  mlr3pipelines::po("nn_relu_1", inplace = TRUE),
  mlr3pipelines::po(
    "nn_max_pool2d_1",
    kernel_size = pool_kernel_size),
  mlr3pipelines::po("nn_flatten"),
  mlr3pipelines::po(
    "nn_linear",
    out_features = n.hidden.units),
  mlr3pipelines::po("nn_head"),
  mlr3pipelines::po(
    "torch_loss",
    mlr3torch::t_loss("cross_entropy")),
  mlr3pipelines::po(
    "torch_optimizer",
    mlr3torch::t_opt("sgd", lr=step_size)),
  mlr3pipelines::po(
    "torch_model_classif",
    batch_size = 32,
    epochs = n.epochs))
graph <- Reduce(mlr3pipelines::concat_graphs, po_list)
(glearner <- mlr3::as_learner(graph))
glearner$base_learner()
```

To use the configure method of the `glearner` object above, we need to
load the mlr3tuning package:

```{r}
measure_list <- mlr3::msrs(c("classif.logloss", "classif.ce"))
glearner$validate <- 0.5
glearner$predict_type <- "prob"
bl <- glearner$base_learner()
bl$callbacks <- list(mlr3torch::t_clbk("history"))
bl$param_set$values$measures_train <- measure_list
bl$param_set$values$measures_valid <- measure_list
glearner$base_learner()

## glearner$configure( #https://github.com/mlr-org/mlr3torch-course/issues/3
##   validate = 0.5,
##   callbacks = mlr3torch::t_clbk("history"),
##   predict_type = "prob",
##   measures_valid = measure_list,
##   measures_train = measure_list)

```

[`TaskClassif_mnist.R`](https://github.com/mlr-org/mlr3torch/blob/main/R/TaskClassif_mnist.R) says that image should be a lazy list column?

Figure 5 from that paper shows that

https://cran.r-project.org/web/packages/mlr3torch/readme/README.html

## MRE for issue

```{r}
N.pixels <- 10
N.classes <- 5
N.features <- 100
N.images <- 200
set.seed(1)
my.X.mat <- matrix(runif(N.features*N.images), N.images, N.features)
my.df <- data.frame(y=factor(1:N.classes), my.X.mat)
my.task <- mlr3::TaskClassif$new("MyTask", my.df, target="y")
library(mlr3pipelines)
library(mlr3torch)
graph <- mlr3pipelines::po("select", selector = selector_type(c("numeric", "integer"))),
  mlr3pipelines::po("torch_ingress_num"),
  mlr3pipelines::po("nn_reshape", shape=c(-1,1,N.pixels,N.pixels)),
  mlr3pipelines::po("nn_conv2d_1", out_channels = 20, kernel_size = 3),
  mlr3pipelines::po("nn_relu_1", inplace = TRUE),
  mlr3pipelines::po("nn_max_pool2d_1", kernel_size = 2),
  mlr3pipelines::po("nn_flatten"),
  mlr3pipelines::po("nn_linear", out_features = 100),
  mlr3pipelines::po("nn_head"),
  mlr3pipelines::po("torch_loss", t_loss("cross_entropy")),
  mlr3pipelines::po("torch_optimizer", t_opt("sgd", lr=0.01)),
  mlr3pipelines::po("torch_model_classif", batch_size = 25, epochs = 2L)
graph$train(my.task)
graph$predict(my.task)

```

## Custom loss function

From `?mlr3torch::TorchLoss` I got

```{r}
torch_loss = mlr3torch::TorchLoss$new(
  torch_loss = torch::nn_mse_loss,
  task_types = "regr")
```

which implies that I need to make my own version of
`torch::nn_mse_loss`. Its definition is in
[nn-loss.R](https://github.com/mlverse/torch/blob/main/R/nn-loss.R),

```{r}
my_mse_loss <- torch::nn_module(
  "my_mse_loss",
  inherit = torch:::nn_loss,
  initialize = function(reduction = "mean") {
    super$initialize(reduction = reduction)
  },
  forward = function(input, target) {
    torch::nnf_mse_loss(input, target, reduction = self$reduction)
  }
)
```

Note that we have to use triple colon syntax above, `torch:::nn_loss`.
A work-around is below,

```{r}
my_mse_loss <- torch::nn_module(
  "my_mse_loss",
  inherit = torch::nn_mse_loss,
  initialize = function(reduction = "mean") {
    super$initialize(reduction = reduction)
  },
  forward = function(input, target) {
    torch::nnf_mse_loss(input, target, reduction = self$reduction)
  }
)
lfun <- my_mse_loss()
lfun(torch::torch_tensor(2), torch::torch_tensor(-3))
```

So our custom AUM loss can be defined as below:

```{r}
ROC_curve <- function(pred_tensor, label_tensor){
  is_positive = label_tensor == 1
  is_negative = label_tensor != 1
  fn_diff = torch::torch_where(is_positive, -1, 0)
  fp_diff = torch::torch_where(is_positive, 0, 1)
  thresh_tensor = -pred_tensor$flatten()
  sorted_indices = torch::torch_argsort(thresh_tensor)
  fp_denom = torch::torch_sum(is_negative) #or 1 for AUM based on count instead of rate
  fn_denom = torch::torch_sum(is_positive) #or 1 for AUM based on count instead of rate
  sorted_fp_cum = fp_diff[sorted_indices]$cumsum(dim=1)/fp_denom
  sorted_fn_cum = -fn_diff[sorted_indices]$flip(1)$cumsum(dim=1)$flip(1)/fn_denom
  sorted_thresh = thresh_tensor[sorted_indices]
  sorted_is_diff = sorted_thresh$diff() != 0
  sorted_fp_end = torch::torch_cat(c(sorted_is_diff, torch::torch_tensor(TRUE)))
  sorted_fn_end = torch::torch_cat(c(torch::torch_tensor(TRUE), sorted_is_diff))
  uniq_thresh = sorted_thresh[sorted_fp_end]
  uniq_fp_after = sorted_fp_cum[sorted_fp_end]
  uniq_fn_before = sorted_fn_cum[sorted_fn_end]
  FPR = torch::torch_cat(c(torch::torch_tensor(0.0), uniq_fp_after))
  FNR = torch::torch_cat(c(uniq_fn_before, torch::torch_tensor(0.0)))
  list(
    FPR=FPR,
    FNR=FNR,
    TPR=1 - FNR,
    "min(FPR,FNR)"=torch::torch_minimum(FPR, FNR),
    min_constant=torch::torch_cat(c(torch::torch_tensor(-Inf), uniq_thresh)),
    max_constant=torch::torch_cat(c(uniq_thresh, torch::torch_tensor(Inf))))
}
Proposed_AUM <- function(pred_tensor, label_tensor){
  roc = ROC_curve(pred_tensor, label_tensor)
  min_FPR_FNR = roc[["min(FPR,FNR)"]][2:-2]
  constant_diff = roc$min_constant[2:N]$diff()
  torch::torch_sum(min_FPR_FNR * constant_diff)
}
nn_AUM_loss <- torch::nn_module(
  "nn_AUM_loss",
  inherit = torch::nn_mse_loss,
  initialize = function() {
    super$initialize()
  },
  forward = function(input, target) {
    Proposed_AUM(input, target)
  }
)
afun <- nn_AUM_loss()
afun(torch::torch_tensor(c(5,-5)), torch::torch_tensor(c(0,1)))
```

So below is the mlr3torch version,

```{r}
mlr3torch_AUM_loss = mlr3torch::TorchLoss$new(
  torch_loss = nn_AUM_loss,
  task_types = "classif")
po_AUM <- mlr3pipelines::po("torch_loss", mlr3torch_AUM_loss)
```

## Conclusions

TODO

## Session info

```{r}
sessionInfo()
```

