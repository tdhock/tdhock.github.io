---
layout: post
title: Cross-validation with neural networks
description: Demonstration of mlr3torch + mlr3resampling
---

```{r Ropts, echo=FALSE, results='hide'}
repo.dir <- normalizePath("..")
post.id <- "2024-10-30-mlr3torch"
fig.path <- paste0(file.path(repo.dir, "assets", "img", post.id), "/")
dir.create(fig.path, showWarnings = FALSE, recursive = TRUE)
knitr::opts_chunk$set(
  dpi=100,
  fig.path=fig.path,
  fig.width=10, ## TODO python figures wider? look at prev issue.
  fig.process=function(path)sub(repo.dir, "", path, fixed=TRUE),
  fig.height=4)
in_render <- !is.null(knitr::opts_knit$get('rmarkdown.pandoc.to'))
in_knit <- isTRUE(getOption('knitr.in.progress'))
options(width=120)
if(FALSE){
  knitr::knit(paste0(post.id, ".Rmd"))
}
```

The goal of this post is to show how to use the mlr3torch package in R
with AUM (Area Under Min of False Positive and False Negative rates,
our newly Proposed surrogate loss for ROC curve optimization), in
combination with the new cross-validation methods we proposed in our
[SOAK paper](https://arxiv.org/abs/2410.08643).

## Introduction 

Last Friday I gave a talk at [MILA](https://mila.quebec/en), [Two new
algorithms for scientific applications of machine
learning](https://github.com/tdhock/two-new-algos-sci-ml/tree/main?tab=readme-ov-file#title-abstract-slides).
The first algorithm that I discussed is [SOAK: Same/Other/All K-fold
cross-validation for estimating similarity of patterns in data
subsets](https://arxiv.org/abs/2410.08643). One simple
demonstration of the algorithm involves three image classification benchmark data sets. Code below adapted from [my github repo](https://github.com/tdhock/cv-same-other-paper/blob/main/data_Classif_MNIST_other.R):

```{r}
other.name.vec <- c("EMNIST", "FashionMNIST")
data.name.vec <- c(other.name.vec, "MNIST")
```

First we download those data sets.

```{r}
prefix <- "https://rcdata.nau.edu/genomic-ml/cv-same-other-paper/data_Classif/"
data_Classif <- "~/projects/cv-same-other-paper/data_Classif"
options(timeout = 600)#seconds
for(data.name in data.name.vec){
  data.csv <- paste0(data.name, ".csv")
  local.csv <- file.path(data_Classif, data.csv)
  if(!file.exists(local.csv)){
    remote.csv <- paste0(prefix, data.csv)
    download.file(remote.csv, local.csv)
  }
}
```

Next we read these data into R (only the first few rows, for
demonstration purposes).

```{r}
data.list <- list()
library(data.table)
for(data.name in data.name.vec){
  data.csv <- paste0(data.name, ".csv")
  local.csv <- file.path(data_Classif, data.csv)
  data.list[[data.name]] <- fread(local.csv, nrows = 1000)
}
```

Next, we plot an example of each class. To do that in the ggplot
framework, we need to create a data frame with one row per pixel to
display, as in the code below.

```{r}
n.pixels <- 28
pseq <- 1:n.pixels
(one.ex.dt <- data.table(Data=data.name.vec)[, {
  data.list[[Data]][, data.table(
    intensity=unlist(.SD[1]),
    pixel_j=rep(pseq, n.pixels),
    pixel_i=rep(pseq, each=n.pixels)
  ), by=y, .SDcols=patterns("[0-9]")]
}, by=Data])
```

We can visualize the images by using the ggplot code below.

```{r plot-images}
library(ggplot2)
ggplot()+
  theme_bw()+
  theme(panel.spacing=grid::unit(0,"lines"))+
  scale_y_reverse()+
  scale_fill_gradient(low="white",high="black")+
  geom_tile(aes(
    pixel_j, pixel_i, fill=intensity),
    data=one.ex.dt)+
  facet_grid(Data ~ y)+
  coord_equal()
```

We see in the image above that the EMNIST digits are transposed
(rotated 90 degrees and flipped) with respect to the MNIST digits.
Correction below.

```{r plot-EMNIST-rot}
data.list$EMNIST_rot <- data.list$EMNIST[,c(
  1,2,as.integer(matrix(seq(1,n.pixels^2),n.pixels,n.pixels,byrow=TRUE))+2
),with=FALSE]
(one.ex.dt <- data.table(Data=names(data.list))[, {
  data.list[[Data]][, data.table(
    intensity=unlist(.SD[1]),
    pixel_j=rep(pseq, n.pixels),
    pixel_i=rep(pseq, each=n.pixels)
  ), by=y, .SDcols=patterns("[0-9]")]
}, by=Data])
ggplot()+
  theme_bw()+
  theme(panel.spacing=grid::unit(0,"lines"))+
  scale_y_reverse()+
  scale_fill_gradient(low="white",high="black")+
  geom_tile(aes(
    pixel_j, pixel_i, fill=intensity),
    data=one.ex.dt)+
  facet_grid(Data ~ y)+
  coord_equal()
```

Above we see the `EMNIST_rot` data in the same orientation as the `MNIST` data.

## Convert data to torch tensors

In my [Res Baz 2023
tutorial](https://rcdata.nau.edu/genomic-ml/2023-res-baz-az/2023-04-19-deep-learning.html),
I explained how to use torch in R. The first step is to convert the
data from R to a torch tensor.

```{r}
ex.dt <- data.list$FashionMNIST
ex.X.mat <- as.matrix(ex.dt[,-(1:2),with=FALSE])
ex.X.array <- array(ex.X.mat, c(nrow(ex.dt), 1, n.pixels, n.pixels))
ex.X.tensor <- torch::torch_tensor(ex.X.array)
ex.X.tensor$shape
(ex.y.tensor <- torch::torch_tensor(ex.dt$y+1L, torch::torch_long()))
```

The data above represents a set of images in torch. Note that there are
four dimensions used to represent the images:

* the first dimension represents the different images (`nrow(ex.dt)` elements in
  the example above, one for each image).
* the second dimension represents the color channels (1 in the example
  above, for grayscale images).
* the third and fourth dimensions represent the height and width of
  the image in pixels (28 in the example above).

## torch linear model

A linear model is defined in the code below.

```{r}
torch::torch_manual_seed(1)
n.features <- ncol(ex.X.mat)
n.classes <- 10
seq_linear_model <- torch::nn_sequential(
  torch::nn_flatten(),
  torch::nn_linear(n.features, n.classes))
two.X.tensor <- ex.X.tensor[1:2,,,]
(seq_linear_model_pred <- seq_linear_model(two.X.tensor))
```

The prediction of the linear model is a tensor with two rows and ten
columns (one output column for each class). To do learning we need to
call backward on the result of a loss function, as in the code below.

```{r}
seq_linear_model$parameters[[2]]$grad
celoss <- torch::nn_cross_entropy_loss()
two.y.tensor <- ex.y.tensor[1:2]
(seq_linear_model_loss <- celoss(seq_linear_model_pred, two.y.tensor))
seq_linear_model_loss$backward()
seq_linear_model$parameters[[2]]$grad
```

Note in the output above that `grad` is undefined at first, and then
defined after having called `backward()`.

## Learning with linear model

For learning we should first divide train data into subtrain and validation.

```{r}
set_names <- c("validation", "subtrain")
set_vec <- rep(set_names, l=nrow(ex.dt))
table(set_vec, torch::as_array(ex.y.tensor))
```

The table above shows that there are about an equal number of observations in each class and set.
Then we can use a gradient descent learning for loop,

```{r plot-torch-linear}
n.epochs <- 1000
step_size <- 0.1
optimizer <- torch::optim_sgd(seq_linear_model$parameters, lr=step_size)
loss_dt_list <- list()
for(epoch in 1:n.epochs){
  set_loss_list <- list()
  for(set_name in set_names){
    is_set <- set_vec==set_name
    set_pred <- seq_linear_model(ex.X.tensor[is_set,,,])
    set_y <- ex.y.tensor[is_set]
    is_error <- set_y != set_pred$argmax(dim=2)
    N_errors <- torch::as_array(is_error$sum())
    set_loss_list[[set_name]] <- celoss(set_pred, set_y)
    loss_dt_list[[paste(epoch, set_name)]] <- data.table(
      epoch, set_name=factor(set_name, set_names),
      variable=c("error_percent","loss"),
      value=c(
        100*N_errors/length(is_error),
        torch::as_array(set_loss_list[[set_name]])))
  }
  optimizer$zero_grad()
  set_loss_list$subtrain$backward()
  optimizer$step()
}
(loss_dt <- rbindlist(loss_dt_list))

(min_dt <- loss_dt[, .SD[which.min(value)], by=.(variable,set_name)])
ggplot()+
  geom_line(aes(
    epoch, value, color=set_name),
    data=loss_dt)+
  geom_point(aes(
    epoch, value, color=set_name),
    shape=21,
    fill="white",
    data=min_dt)+
  facet_grid(variable ~ ., scales="free")
```

The results above show that the best validation error is about 16%,
around 300 epochs.

## Comparison with glmnet

Another implementation of linear models is given in the glmnet
package, which has automatic regularization parameter tuning via the
`cv.glmnet` function, but below we use the `glmnet` function for a
more direct comparison with what we did using torch above.

```{r plot-glmnet}
subtrain.X <- ex.X.mat[set_vec=="subtrain",]
ex.y.fac <- factor(torch::as_array(ex.y.tensor))
subtrain.y <- ex.y.fac[set_vec=="subtrain"]
fit_glmnet <- glmnet::glmnet(subtrain.X, subtrain.y, family="multinomial")
pred_glmnet <- predict(fit_glmnet, ex.X.mat, type="class")
err_glmnet_mat <- pred_glmnet != ex.y.fac

err_glmnet_dt_list <- list()
for(set_name in set_names){
  err_glmnet_dt_list[[set_name]] <- data.table(
    set_name=factor(set_name, set_names),
    penalty=fit_glmnet$lambda,
    complexity=-log10(fit_glmnet$lambda),
    error_percent=colMeans(err_glmnet_mat[set_vec==set_name,])*100)
}
err_glmnet_dt <- rbindlist(err_glmnet_dt_list)
(min_glmnet_dt <- err_glmnet_dt[, .SD[which.min(error_percent)], by=set_name])
ggplot()+
  theme_bw()+
  geom_line(aes(
    complexity, error_percent, color=set_name),
    data=err_glmnet_dt)+
  geom_point(aes(
    complexity, error_percent, color=set_name),
    data=min_glmnet_dt,
    shape=21,
    fill="white")+
  scale_x_log10(
    "Model complexity = -log10(L1 regularization parameter lambda)")
```

The figure above shows that the min validation error is about 23%,
slightly larger than the torch linear model.

## mlr3torch linear models

The mlr3torch package provides an alternative way of defining torch
models, using the
[pipeops](https://mlr3torch.mlr-org.com/articles/pipeop_torch.html)
framework. The advantage of this approach is that each model can be
converted to a `Learner` object, which can be run alongside other
non-torch learners (such as glmnet), on lots of different data sets
and train/test splits (in parallel using mlr3batchmark). They can be
even run using my newly proposed SOAK algorithm (Same/Other/All K-fold
cross-validation), which can be implemented using the code below.

```{r}
soak <- mlr3resampling::ResamplingSameOtherSizesCV$new()
```

Note that it is important to run the line of code above, before
creating the tasks using the code below, because `mlr3resampling`
package needs to be loaded in order to avoid an error (`subset` is not
a valid column role).
The code below converts each data set of interest to a Task.

```{r}
task.list <- list()
for(other.name in c("EMNIST_rot","FashionMNIST")){
  ipair.dt.list <- list()
  for(Data in c(other.name,"MNIST")){
    one.dt <- data.list[[Data]][,-1][, y := factor(y)][]
    setnames(one.dt, c("y", paste0("X", names(one.dt)[-1])))
    ipair.dt.list[[Data]] <- data.table(Data, one.dt)
  }
  ipair.dt <- rbindlist(ipair.dt.list, use.names=FALSE)
  ipair.name <- paste0("MNIST_",other.name)
  itask <- mlr3::TaskClassif$new(
    ipair.name, ipair.dt, target="y")
  itask$col_roles$stratum <- "y"
  itask$col_roles$subset <- "Data"
  itask$col_roles$feature <- paste0("X",seq(0,n.pixels^2-1))
  task.list[[ipair.name]] <- itask
}
task.list
```

Note that the code above produces a list of two tasks, each of which
has two subsets.

* `MNIST_FashionMNIST` has two subsets: half MNIST images (digits),
  half FashionMNIST images (clothing). It should not be possible to
  get good accuracy when training on MNIST and predicting on
  FashionMNIST.
* `MNIST_EMNIST_rot` has two subsets: half MNIST images (digits), half
  EMNIST images (also digits), so it may be possible to get good
  prediction, even though the two data sets have different
  pre-processing methods (slightly different position / size of digit
  images).
  
### Define linear model using mlr3 MLP learner

To define a torch linear model in the mlr3 framework,
[@sebffischer](https://github.com/mlr-org/mlr3torch/issues/364#issuecomment-2742682366)
advised me to first define a MLP, designating the number of epochs to
tune, with patience equal to the number of total epochs (meaning it
will always go up to the total number of epochs). Docs for this are in
[mlr3 book chapter
15](https://mlr3book.mlr-org.com/chapters/chapter15/predsets_valid_inttune.html),
which explains about internal tuning via parameters like
`early_stopping_rounds` and `patience`.

```{r}
measure_list <- mlr3::msrs(c("classif.logloss", "classif.ce"))
mlp_learner = mlr3::lrn("classif.mlp",
  epochs = paradox::to_tune(upper = n.epochs, internal = TRUE),
  measures_train = measure_list,
  measures_valid = measure_list,
  patience = n.epochs,
  optimizer = mlr3torch::t_opt("sgd", lr = step_size),
  callbacks = mlr3torch::t_clbk("history"),
  batch_size = N.images,
  validate = 0.5,
  predict_type = "prob")
```

Below we create an auto tuner learner based on the MLP learner,
instructing it to use the (first) internal validation score as the
measure to optimize.

```{r}
mlp_learner_auto = mlr3tuning::auto_tuner(
  learner = mlp_learner,
  tuner = mlr3tuning::tnr("internal"),
  resampling = mlr3::rsmp("insample"),# the train/valid split is handled by the learner itself
  measure = mlr3::msr("internal_valid_score", minimize = TRUE),# for the optimal model we will use the internal validation score computed during training
  term_evals = 1,# early stopping just needs a single run
  id="linear_mlp",
  store_models = TRUE)# so we can access the history afterwards
mlp_learner_auto$train(task.list$MNIST_FashionMNIST)
mlp_learner_auto$model$learner$model$network
```

Below we reshape and plot the epoch-specific measures which were used
to select the best number of epochs:

```{r plot-mlp}
pat <- function(...){
  old2new <- c(...)
  if(is.null(names(old2new))){
    names(old2new) <- old2new
  }
  to.rep <- names(old2new)==""
  names(old2new)[to.rep] <- old2new[to.rep]
  list(
    paste(names(old2new), collapse="|"),
    function(x)factor(old2new[x], old2new))
}
melt_history <- function(DT)nc::capture_melt_single(
  DT,
  set=pat(valid="validation", train="subtrain"),
  ".classif.",
  measure=pat(ce="error_prop", auc="AUC", "logloss"))
(measure_long <- melt_history(
  mlp_learner_auto$archive$learners(1)[[1L]]$model$callbacks$history))
(selected_row <- as.data.table(
  mlp_learner_auto$tuning_result$internal_tuned_values[[1]]))
ggplot()+
  facet_grid(measure ~ ., scales="free")+
  geom_vline(aes(
    xintercept=epochs),
    data=selected_row)+
  geom_line(aes(
    epoch, value, color=set),
    data=measure_long)
```

The figure above has learning curves that look reasonable.

### Define mlr3 linear model using pipe operations

A more flexible way of defining a neural network involves pipe
operations, as explained in
[mlr3torch-course-ch6](https://mlr-org.github.io/mlr3torch-course/notebooks/6-mlr3torch.html)
explains how to mlr3torch pipe operations to define a neural network.
I understand from `?mlr3torch::PipeOpTorchIngressNumeric` that we need
`po("torch_ingress_num")` to convert regular R features to torch
tensors. And we need `nn_head` pipeop at the end of the network, which
automatically determines the right number of output units, based on
the loss function. Whereas the mlr3 docs suggest using `%>>%` to
combine pipe operations, I use a list/Reduce below, to emphasize which
functions are defined in which packages.

```{r}
po_list_linear_ce <- list(
  mlr3pipelines::po(
    "select",
    selector = mlr3pipelines::selector_type(c("numeric", "integer"))),
  mlr3torch::PipeOpTorchIngressNumeric$new(),
  mlr3pipelines::po("nn_head"),
  mlr3pipelines::po(
    "torch_loss",
    mlr3torch::t_loss("cross_entropy")),
  mlr3pipelines::po(
    "torch_optimizer",
    mlr3torch::t_opt("sgd", lr=step_size)),
  mlr3pipelines::po(
    "torch_callbacks",
    mlr3torch::t_clbk("history")),
  mlr3pipelines::po(
    "torch_model_classif",
    batch_size = N.images,
    patience=n.epochs,
    measures_valid=measure_list,
    measures_train=measure_list,
    predict_type="prob",
    epochs = paradox::to_tune(upper = n.epochs, internal = TRUE)))
(graph_linear_ce <- Reduce(mlr3pipelines::concat_graphs, po_list_linear_ce))
```

Code above defines the graph learner object, and code below converts
it to a learner object. Note the `set_validate` is important to use
with pipe operations, to avoid some errors.

```{r}
(lgearner_linear_ce <- mlr3::as_learner(graph_linear_ce))
mlr3::set_validate(glearner_linear_ce, validate = 0.5)
```

The code below defines an auto tuner based on the graph learner above. 
It is the same as the corresponding code in the previous section with the MLP.

```{r}
glearner_auto = mlr3tuning::auto_tuner(
  learner = glearner_linear_ce,
  tuner = mlr3tuning::tnr("internal"),
  resampling = mlr3::rsmp("insample"),
  measure = mlr3::msr("internal_valid_score", minimize = TRUE),
  term_evals = 1,
  id="linear_graph",
  store_models = TRUE)
glearner_auto$train(task.list$MNIST_FashionMNIST)
glearner_auto$base_learner()$model$network
```

After training above, we visualize the model training below.

```{r plot-pipe}
glearner_model <- glearner_auto$archive$learners(1)[[1]]$model
(glearner_long <- melt_history(
  glearner_model$torch_model_classif$model$callbacks$history))
(glearner_selected <- as.data.table(
  glearner_auto$tuning_result$internal_tuned_values[[1]]))
ggplot()+
  facet_grid(measure ~ ., scales="free")+
  geom_vline(aes(
    xintercept=torch_model_classif.epochs),
    data=glearner_selected)+
  geom_line(aes(
    epoch, value, color=set),
    data=glearner_long)
```

Again the plot looks reasonable, and consistent with our previous
results.

## Benchmark experiment

Is the torch linear model as accurate as the glmnet linear model?
Let's find out. First we create a grid of learners and tasks.

```{r}
learner.list <- list(
  glearner_auto,
  mlp_learner_auto,
  mlr3::LearnerClassifFeatureless$new()$configure(id="featureless"))
for(s_param in c("min", "1se")){
  learner.list[[s_param]] <- mlr3learners::LearnerClassifCVGlmnet$new()$configure(
    s=paste0("lambda.",s_param),
    id=paste0("cv_glmnet_",s_param))
}
(bench.grid <- mlr3::benchmark_grid(
  task.list,
  learner.list,
  soak))
```

Below declare a future plan for computation in parallel on this
machine. For larger experiments you can use `mlr3batchmark` to compute
in parallel on a cluster, see my blog on the [importance of
hyper-parameter
tuning](https://tdhock.github.io/blog/2024/hyper-parameter-tuning/).
Then we run/cache the benchmark:

```{r}
cache.RData <- "2024-10-30-mlr3torch-benchmark.RData"
if(file.exists(cache.RData)){
  load(cache.RData)
}else{#code below should be run interactively.
  if(on.cluster){
    reg.dir <- "2024-10-30-mlr3torch-benchmark"
    unlink(reg.dir, recursive=TRUE)
    reg = batchtools::makeExperimentRegistry(
      file.dir = reg.dir,
      seed = 1,
      packages = "mlr3verse"
    )
    mlr3batchmark::batchmark(
      bench.grid, store_models = TRUE, reg=reg)
    job.table <- batchtools::getJobTable(reg=reg)
    chunks <- data.frame(job.table, chunk=1)
    batchtools::submitJobs(chunks, resources=list(
      walltime = 60*60,#seconds
      memory = 2000,#megabytes per cpu
      ncpus=1,  #>1 for multicore/parallel jobs.
      ntasks=1, #>1 for MPI jobs.
      chunks.as.arrayjobs=TRUE), reg=reg)
    batchtools::getStatus(reg=reg)
    jobs.after <- batchtools::getJobTable(reg=reg)
    table(jobs.after$error)
    ids <- jobs.after[is.na(error), job.id]
    bench.result <- mlr3batchmark::reduceResultsBatchmark(ids, reg = reg)
  }else{
    ## In the code below, we declare a multisession future plan to
    ## compute each benchmark iteration in parallel on this computer
    ## (data set, learning algorithm, cross-validation fold). For a
    ## few dozen iterations, using the multisession backend is
    ## probably sufficient (I have 12 CPUs on my work PC).
    if(require(future))plan("multisession")
    bench.result <- mlr3::benchmark(bench.grid, store_models = TRUE)
  }
  save(bench.result, file=cache.RData)
}
```

Then we compute and plot a table of evaluation metrics:

```{r full-test-error, fig.height=4.5}
score_dt <- mlr3resampling::score(bench.result)[
, percent_error := 100*classif.ce
][]
score_dt[, .(task_id, test.subset, train.subsets, algorithm, percent_error)]

ggplot()+
  geom_point(aes(
    percent_error, algorithm),
    shape=1,
    data=score_dt)+
  facet_grid(train.subsets ~ task_id + test.subset, labeller=label_both)
```

There is a lot of information in the plot above. It could be
simplified by taking the mean and SD over the three folds:

```{r mean-sd, fig.height=4.5}
(score_stats <- dcast(
  score_dt,
  algorithm + task_id + test.subset + train.subsets ~ .,
  list(mean, sd),
  value.var="percent_error"))
ggplot()+
  geom_point(aes(
    percent_error_mean, algorithm),
    shape=1,
    data=score_stats)+
  geom_segment(aes(
    percent_error_mean+percent_error_sd, algorithm,
    xend=percent_error_mean-percent_error_sd, yend=algorithm),
    data=score_stats)+
  facet_grid(train.subsets ~ task_id + test.subset, labeller=label_both)
```

The plot above shows means and standard deviations for all the models.

### Does training on the other subset work?

We focus only on predicting MNIST, after training on another data set.

```{r train-other, fig.height=2}
score_other <- score_stats[test.subset=="MNIST" & train.subsets=="other"]
ggplot()+
  geom_point(aes(
    percent_error_mean, algorithm),
    shape=1,
    data=score_other)+
  geom_segment(aes(
    percent_error_mean+percent_error_sd, algorithm,
    xend=percent_error_mean-percent_error_sd, yend=algorithm),
    data=score_other)+
  facet_grid(. ~ task_id, labeller=label_both)+
  scale_x_continuous(
    "Test error on MNIST (mean +/- SD over 3 folds), after training on Other subset (EMNIST/Fashion)",
    limits=c(40,100),
    breaks=seq(40,100,by=10))
```

The figure above shows that
* training on `EMNIST_rot` has significantly smaller error rates than
  featureless, indicating that these data are similar enough to MNIST,
  for the linear model to be able to learn something useful.
* torch linear models are a bit more accurate than `cv_glmnet`
  (surprising, since both are linear models).
* there is not much difference between the two torch linear models (as expected).
* there is not much difference between the two `cv_glmnet` linear
  models (as expected), although the min variant has a slightly
  smaller error rate (as expected).
* training on `FashionMNIST` has significantly larger error rates than
  featureless, indicating that the data are so different, that the
  linear model does not learn anything relevant for accurate
  predictions on the other subset.

### Comparing Other and Same

Is training on EMNIST as good as training on MNIST, if our goal is
good predictions in MNIST?

```{r same-other-all-mnist, fig.height=2}
score_EMNIST <- score_stats[test.subset=="MNIST" & task_id=="MNIST_EMNIST_rot"]
ggplot()+
  ggtitle("SOAK results for MNIST_EMNIST_rot data")+
  geom_point(aes(
    percent_error_mean, algorithm,
    color=train.subsets),
    shape=1,
    data=score_EMNIST)+
  geom_segment(aes(
    percent_error_mean+percent_error_sd, algorithm,
    color=train.subsets,
    xend=percent_error_mean-percent_error_sd, yend=algorithm),
    data=score_EMNIST)+
  scale_x_continuous(
    "Test error on MNIST (mean +/- SD over 3 folds)",
    limits=c(0,100),
    breaks=seq(0,100,by=10))
```

The figure above indicates that the Other model (training on EMNIST)
has much larger error rates, compared to the Same model (training on
MNIST). These data indicate that the data subsets are not similar
enough for the linear model to fully generalize between subsets.

### Early stopping diagnostic plot

For each of the models we can check if the early stopping
regularization worked reasonably, via code as below.

```{r plot-diag-glearner}
one.glearner <- score_dt[algorithm=="linear_graph"]$learner[[1]]
glearner_model <- one.glearner$archive$learners(1)[[1]]$model
(glearner_long <- melt_history(
  glearner_model$torch_model_classif$model$callbacks$history))
(glearner_selected <- as.data.table(
  one.glearner$tuning_result$internal_tuned_values[[1]]))
ggplot()+
  facet_grid(measure ~ ., scales="free")+
  geom_vline(aes(
    xintercept=torch_model_classif.epochs),
    data=glearner_selected)+
  geom_line(aes(
    epoch, value, color=set),
    data=glearner_long)
```

The figure above shows typical subtrain/validation error curves, with
an optimal number of epochs chosen reasonably (an intermediate value
that minimizes the log loss).

## Conclusions

We have shown how mlr3torch can be used to define neural networks,
then run machine learning benchmark experiments in parallel, then
interpret results using figures.

## Session info

```{r}
sessionInfo()
```
