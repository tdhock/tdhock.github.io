---
layout: post
title: Cross-validation with neural networks
description: Demonstration of mlr3torch + mlr3resampling
---

```{r Ropts, echo=FALSE, results='hide'}
repo.dir <- normalizePath("..")
post.id <- "2024-10-30-mlr3torch"
fig.path <- paste0(file.path(repo.dir, "assets", "img", post.id), "/")
dir.create(fig.path, showWarnings = FALSE, recursive = TRUE)
knitr::opts_chunk$set(
  dpi=100,
  fig.path=fig.path,
  fig.width=10, ## TODO python figures wider? look at prev issue.
  fig.process=function(path)sub(repo.dir, "", path, fixed=TRUE),
  fig.height=4)
conda.env <- "2023-08-deep-learning"
conda.env <- "torch-aum"
RETICULATE_PYTHON <- sprintf(if(.Platform$OS.type=="unix")
  ##"/home/tdhock/.local/share/r-miniconda/envs/%s/bin/python"
  "/home/tdhock/miniconda3/envs/%s/bin/python"
  else "~/AppData/Local/Miniconda3/envs/%s/python.exe", conda.env)
Sys.setenv(RETICULATE_PYTHON=RETICULATE_PYTHON)
##reticulate::use_condaenv(dirname(RETICULATE_PYTHON), required=TRUE)
in_render <- !is.null(knitr::opts_knit$get('rmarkdown.pandoc.to'))
in_knit <- isTRUE(getOption('knitr.in.progress'))
options(width=120)
if(FALSE){
  knitr::knit(paste0(post.id, ".Rmd"))
}
```

The goal of this post is to show how to use the mlr3torch package in R
with AUM (Area Under Min of False Positive and False Negative rates,
our newly Proposed surrogate loss for ROC curve optimization), in
combination with the new cross-validation methods we proposed in our
[SOAK paper](https://arxiv.org/abs/2410.08643).

## Introduction 

Last Friday I gave a talk at [MILA](https://mila.quebec/en), [Two new
algorithms for scientific applications of machine
learning](https://github.com/tdhock/two-new-algos-sci-ml/tree/main?tab=readme-ov-file#title-abstract-slides).
The first algorithm that I discussed is [SOAK: Same/Other/All K-fold
cross-validation for estimating similarity of patterns in data
subsets](https://arxiv.org/abs/2410.08643). One simple
demonstration of the algorithm involves three image classification benchmark data sets. Code below adapted from [my github repo](https://github.com/tdhock/cv-same-other-paper/blob/main/data_Classif_MNIST_other.R):

```{r}
other.name.vec <- c("EMNIST", "FashionMNIST")
data.name.vec <- c(other.name.vec, "MNIST")
```

First we download those data sets.

```{r}
prefix <- "https://rcdata.nau.edu/genomic-ml/cv-same-other-paper/data_Classif/"
data_Classif <- "~/projects/cv-same-other-paper/data_Classif"
options(timeout = 600)#seconds
for(data.name in data.name.vec){
  data.csv <- paste0(data.name, ".csv")
  local.csv <- file.path(data_Classif, data.csv)
  if(!file.exists(local.csv)){
    remote.csv <- paste0(prefix, data.csv)
    download.file(remote.csv, local.csv)
  }
}
```

Next we read these data into R (only the first few rows, for
demonstration purposes).

```{r}
data.list <- list()
library(data.table)
for(data.name in data.name.vec){
  data.csv <- paste0(data.name, ".csv")
  local.csv <- file.path(data_Classif, data.csv)
  data.list[[data.name]] <- fread(local.csv, nrows = 1000)
}
```

Next, we plot an example of each class. To do that in the ggplot
framework, we need to create a data frame with one row per pixel to
display, as in the code below.

```{r}
n.pixels <- 28
pseq <- 1:n.pixels
(one.ex.dt <- data.table(Data=data.name.vec)[, {
  data.list[[Data]][, data.table(
    intensity=unlist(.SD[1]),
    pixel_j=rep(pseq, n.pixels),
    pixel_i=rep(pseq, each=n.pixels)
  ), by=y, .SDcols=patterns("[0-9]")]
}, by=Data])
```

We can visualize the images by using the ggplot code below.

```{r plot-images}
library(ggplot2)
ggplot()+
  theme_bw()+
  theme(panel.spacing=grid::unit(0,"lines"))+
  scale_y_reverse()+
  scale_fill_gradient(low="white",high="black")+
  geom_tile(aes(
    pixel_j, pixel_i, fill=intensity),
    data=one.ex.dt)+
  facet_grid(Data ~ y)+
  coord_equal()
```

We see in the image above that the EMNIST digits are transposed
(rotated 90 degrees and flipped) with respect to the MNIST digits.
Correction below.

```{r plot-EMNIST-rot}
data.list$EMNIST_rot <- data.list$EMNIST[,c(
  1,2,as.integer(matrix(seq(1,n.pixels^2),n.pixels,n.pixels,byrow=TRUE))+2
),with=FALSE]
(one.ex.dt <- data.table(Data=names(data.list))[, {
  data.list[[Data]][, data.table(
    intensity=unlist(.SD[1]),
    pixel_j=rep(pseq, n.pixels),
    pixel_i=rep(pseq, each=n.pixels)
  ), by=y, .SDcols=patterns("[0-9]")]
}, by=Data])
ggplot()+
  theme_bw()+
  theme(panel.spacing=grid::unit(0,"lines"))+
  scale_y_reverse()+
  scale_fill_gradient(low="white",high="black")+
  geom_tile(aes(
    pixel_j, pixel_i, fill=intensity),
    data=one.ex.dt)+
  facet_grid(Data ~ y)+
  coord_equal()
```

Above we see the `EMNIST_rot` data in the same orientation as the `MNIST` data.

## Convert data to torch tensors

In my [Res Baz 2023
tutorial](https://rcdata.nau.edu/genomic-ml/2023-res-baz-az/2023-04-19-deep-learning.html),
I explained how to use torch in R. The first step is to convert the
data from R to a torch tensor.

```{r}
ex.dt <- data.list$FashionMNIST
ex.X.mat <- as.matrix(ex.dt[,-(1:2),with=FALSE])
ex.X.array <- array(ex.X.mat, c(nrow(ex.dt), 1, n.pixels, n.pixels))
ex.X.tensor <- torch::torch_tensor(ex.X.array)
ex.X.tensor$shape
(ex.y.tensor <- torch::torch_tensor(ex.dt$y+1L, torch::torch_long()))
```

The data above represents a set of images in torch. Note that there are
four dimensions used to represent the images:

* the first dimension represents the different images (`nrow(ex.dt)` elements in
  the example above, one for each image).
* the second dimension represents the color channels (1 in the example
  above, for grayscale images).
* the third and fourth dimensions represent the height and width of
  the image in pixels (28 in the example above).

## torch linear model

A linear model is defined in the code below.

```{r}
torch::torch_manual_seed(1)
n.features <- ncol(ex.X.mat)
n.classes <- 10
seq_linear_model <- torch::nn_sequential(
  torch::nn_flatten(),
  torch::nn_linear(n.features, n.classes))
two.X.tensor <- ex.X.tensor[1:2,,,]
(seq_linear_model_pred <- seq_linear_model(two.X.tensor))
```

The prediction of the linear model is a tensor with two rows and ten
columns (one output column for each class). To do learning we need to
call backward on the result of a loss function, as in the code below.

```{r}
seq_linear_model$parameters[[2]]$grad
celoss <- torch::nn_cross_entropy_loss()
two.y.tensor <- ex.y.tensor[1:2]
(seq_linear_model_loss <- celoss(seq_linear_model_pred, two.y.tensor))
seq_linear_model_loss$backward()
seq_linear_model$parameters[[2]]$grad
```

Note in the output above that `grad` is undefined at first, and then
defined after having called `backward()`.

## Learning with linear model

For learning we should first divide train data into subtrain and validation.

```{r}
set_names <- c("validation", "subtrain")
set_vec <- rep(set_names, l=nrow(ex.dt))
table(set_vec, torch::as_array(ex.y.tensor))
```

The table above shows that there are about an equal number of observations in each class and set.
Then we can use a gradient descent learning for loop,

```{r plot-torch-linear}
n.epochs <- 1000
step_size <- 0.1
optimizer <- torch::optim_sgd(seq_linear_model$parameters, lr=step_size)
loss_dt_list <- list()
for(epoch in 1:n.epochs){
  set_loss_list <- list()
  for(set_name in set_names){
    is_set <- set_vec==set_name
    set_pred <- seq_linear_model(ex.X.tensor[is_set,,,])
    set_y <- ex.y.tensor[is_set]
    is_error <- set_y != set_pred$argmax(dim=2)
    N_errors <- torch::as_array(is_error$sum())
    set_loss_list[[set_name]] <- celoss(set_pred, set_y)
    loss_dt_list[[paste(epoch, set_name)]] <- data.table(
      epoch, set_name=factor(set_name, set_names),
      variable=c("error_percent","loss"),
      value=c(
        100*N_errors/length(is_error),
        torch::as_array(set_loss_list[[set_name]])))
  }
  optimizer$zero_grad()
  set_loss_list$subtrain$backward()
  optimizer$step()
}
(loss_dt <- rbindlist(loss_dt_list))

(min_dt <- loss_dt[, .SD[which.min(value)], by=.(variable,set_name)])
ggplot()+
  geom_line(aes(
    epoch, value, color=set_name),
    data=loss_dt)+
  geom_point(aes(
    epoch, value, color=set_name),
    shape=21,
    fill="white",
    data=min_dt)+
  facet_grid(variable ~ ., scales="free")
```

The results above show that the best validation error is about 16%,
around 300 epochs.

## Comparison with glmnet

Another implementation of linear models is given in the glmnet
package, which has automatic regularization parameter tuning via the
`cv.glmnet` function, but below we use the `glmnet` function for a
more direct comparison with what we did using torch above.

```{r plot-glmnet}
subtrain.X <- ex.X.mat[set_vec=="subtrain",]
ex.y.fac <- factor(torch::as_array(ex.y.tensor))
subtrain.y <- ex.y.fac[set_vec=="subtrain"]
fit_glmnet <- glmnet::glmnet(subtrain.X, subtrain.y, family="multinomial")
pred_glmnet <- predict(fit_glmnet, ex.X.mat, type="class")
err_glmnet_mat <- pred_glmnet != ex.y.fac

err_glmnet_dt_list <- list()
for(set_name in set_names){
  err_glmnet_dt_list[[set_name]] <- data.table(
    set_name=factor(set_name, set_names),
    penalty=fit_glmnet$lambda,
    complexity=-log10(fit_glmnet$lambda),
    error_percent=colMeans(err_glmnet_mat[set_vec==set_name,])*100)
}
err_glmnet_dt <- rbindlist(err_glmnet_dt_list)
(min_glmnet_dt <- err_glmnet_dt[, .SD[which.min(error_percent)], by=set_name])
ggplot()+
  theme_bw()+
  geom_line(aes(
    complexity, error_percent, color=set_name),
    data=err_glmnet_dt)+
  geom_point(aes(
    complexity, error_percent, color=set_name),
    data=min_glmnet_dt,
    shape=21,
    fill="white")+
  scale_x_log10()
```

The figure above shows that the min validation error is about 23%,
slightly larger than the torch linear model.

## mlr3torch linear models

The mlr3torch package provides an alternative way of defining torch
models, using the
[pipeops](https://mlr3torch.mlr-org.com/articles/pipeop_torch.html)
framework. The advantage of this approach is that each model can be
converted to a `Learner` object, which can be run alongside other
non-torch learners (such as glmnet), on lots of different data sets
and train/test splits (in parallel using mlr3batchmark). They can be
even run using my newly proposed SOAK algorithm (Same/Other/All K-fold
cross-validation), which can be implemented using the code below.

```{r}
soak <- mlr3resampling::ResamplingSameOtherSizesCV$new()
```

Note that it is important to run the line of code above, before
creating the tasks using the code below, because `mlr3resampling`
package needs to be loaded in order to avoid an error (`subset` is not
a valid column role).
The code below converts each data set of interest to a Task.

```{r}
task.list <- list()
for(other.name in c("EMNIST_rot","FashionMNIST")){
  ipair.dt.list <- list()
  for(Data in c(other.name,"MNIST")){
    one.dt <- data.list[[Data]][,-1][, y := factor(y)][]
    setnames(one.dt, c("y", paste0("X", names(one.dt)[-1])))
    ipair.dt.list[[Data]] <- data.table(Data, one.dt)
  }
  ipair.dt <- rbindlist(ipair.dt.list, use.names=FALSE)
  ipair.name <- paste0("MNIST_",other.name)
  itask <- mlr3::TaskClassif$new(
    ipair.name, ipair.dt, target="y")
  itask$col_roles$stratum <- "y"
  itask$col_roles$subset <- "Data"
  itask$col_roles$feature <- paste0("X",seq(0,n.pixels^2-1))
  task.list[[ipair.name]] <- itask
}
task.list
```

Note that the code above produces a list of two tasks, each of which
has two subsets.

* `MNIST_FashionMNIST` has two subsets: half MNIST images (digits),
  half FashionMNIST images (clothing). It should not be possible to
  get good accuracy when training on MNIST and predicting on
  FashionMNIST.
* `MNIST_EMNIST_rot` has two subsets: half MNIST images (digits), half
  EMNIST images (also digits), so it may be possible to get good
  prediction, even though the two data sets have different
  pre-processing methods (slightly different position / size of digit
  images).
  
### Define linear model using mlr3 MLP learner

To define a torch linear model in the mlr3 framework,
[@sebffischer](https://github.com/mlr-org/mlr3torch/issues/364#issuecomment-2742682366)
advised me to first define a MLP, designating the number of epochs to
tune, with patience equal to the number of total epochs (meaning it
will always go up to the total number of epochs). Docs for this are in
[mlr3 book chapter
15](https://mlr3book.mlr-org.com/chapters/chapter15/predsets_valid_inttune.html),
which explains about internal tuning via parameters like
`early_stopping_rounds` and `patience`.

```{r}
measure_list <- mlr3::msrs(c("classif.logloss", "classif.ce"))
mlp_learner = mlr3::lrn("classif.mlp",
  epochs = paradox::to_tune(upper = n.epochs, internal = TRUE),
  measures_train = measure_list,
  measures_valid = measure_list,
  patience = n.epochs,
  optimizer = mlr3torch::t_opt("sgd", lr = step_size),
  callbacks = mlr3torch::t_clbk("history"),
  batch_size = N.images,
  validate = 0.5,
  predict_type = "prob")
mlp_learner$predict_sets = NULL
```

Below we create an auto tuner learner based on the MLP learner,
instructing it to use the (first) internal validation score as the
measure to optimize.

```{r}
mlp_learner_auto = mlr3tuning::auto_tuner(
  learner = mlp_learner,
  tuner = mlr3tuning::tnr("internal"),
  resampling = mlr3::rsmp("insample"),# the train/valid split is handled by the learner itself
  measure = mlr3::msr("internal_valid_score", minimize = TRUE),# for the optimal model we will use the internal validation score computed during training
  term_evals = 1,# early stopping just needs a single run
  store_models = TRUE)# so we can access the history afterwards
mlp_learner_auto$train(task.list$MNIST_FashionMNIST)
mlp_learner_auto$model$learner$model$network
```

Below we reshape and plot the epoch-specific measures which were used
to select the best number of epochs:

```{r plot-mlp}
pat <- function(...){
  old2new <- c(...)
  if(is.null(names(old2new))){
    names(old2new) <- old2new
  }
  to.rep <- names(old2new)==""
  names(old2new)[to.rep] <- old2new[to.rep]
  list(
    paste(names(old2new), collapse="|"),
    function(x)factor(old2new[x], old2new))
}
melt_history <- function(DT)nc::capture_melt_single(
  DT,
  set=pat(valid="validation", train="subtrain"),
  ".classif.",
  measure=pat(ce="error_prop", auc="AUC", "logloss"))
(measure_long <- melt_history(
  mlp_learner_auto$archive$learners(1)[[1L]]$model$callbacks$history))
(selected_row <- as.data.table(
  mlp_learner_auto$tuning_result$internal_tuned_values[[1]]))
ggplot()+
  facet_grid(measure ~ ., scales="free")+
  geom_vline(aes(
    xintercept=epochs),
    data=selected_row)+
  geom_line(aes(
    epoch, value, color=set),
    data=measure_long)
```

The figure above has learning curves that look reasonable.

### Define mlr3 linear model using pipe operations

A more flexible way of defining a neural network involves pipe
operations, as explained in
[mlr3torch-course-ch6](https://mlr-org.github.io/mlr3torch-course/notebooks/6-mlr3torch.html)
explains how to mlr3torch pipe operations to define a neural network.
I understand from `?mlr3torch::PipeOpTorchIngressNumeric` that we need
`po("torch_ingress_num")` to convert regular R features to torch
tensors. And we need `nn_head` pipeop at the end of the network, which
automatically determines the right number of output units, based on
the loss function. Whereas the mlr3 docs suggest using `%>>%` to
combine pipe operations, I use a list/Reduce below, to emphasize which
functions are defined in which packages.

```{r}
po_list_linear_ce <- list(
  mlr3pipelines::po(
    "select",
    selector = mlr3pipelines::selector_type(c("numeric", "integer"))),
  mlr3torch::PipeOpTorchIngressNumeric$new(),
  mlr3pipelines::po("nn_head"),
  mlr3pipelines::po(
    "torch_loss",
    mlr3torch::t_loss("cross_entropy")),
  mlr3pipelines::po(
    "torch_optimizer",
    mlr3torch::t_opt("sgd", lr=step_size)),
  mlr3pipelines::po(
    "torch_callbacks",
    mlr3torch::t_clbk("history")),
  mlr3pipelines::po(
    "torch_model_classif",
    batch_size = N.images,
    patience=n.epochs,
    measures_valid=measure_list,
    measures_train=measure_list,
    predict_type="prob",
    epochs = paradox::to_tune(upper = n.epochs, internal = TRUE)))
(graph_linear_ce <- Reduce(mlr3pipelines::concat_graphs, po_list_linear_ce))
```

Code above defines the graph learner object, and code below converts
it to a learner object. Note the `set_validate` is important to use
with pipe operations, to avoid some errors.

```{r}
(glearner_linear_ce <- mlr3::as_learner(graph_linear_ce))
mlr3::set_validate(glearner_linear_ce, validate = 0.5)
glearner_linear_ce$predict_sets = NULL
```

The code below defines an auto tuner based on the graph learner above. 
It is the same as the corresponding code in the previous section with the MLP.

```{r}
glearner_auto = mlr3tuning::auto_tuner(
  learner = glearner_linear_ce,
  tuner = mlr3tuning::tnr("internal"),
  resampling = mlr3::rsmp("insample"),
  measure = mlr3::msr("internal_valid_score", minimize = TRUE),
  term_evals = 1,
  store_models = TRUE)
glearner_auto$train(task.list$MNIST_FashionMNIST)
glearner_auto$base_learner()$model$network
```

After training above, we visualize the model training below.

```{r plot-pipe}
glearner_model <- glearner_auto$archive$learners(1)[[1]]$model
(glearner_long <- melt_history(
  glearner_model$torch_model_classif$model$callbacks$history))
(glearner_selected <- as.data.table(
  glearner_auto$tuning_result$internal_tuned_values[[1]]))
ggplot()+
  facet_grid(measure ~ ., scales="free")+
  geom_vline(aes(
    xintercept=torch_model_classif.epochs),
    data=glearner_selected)+
  geom_line(aes(
    epoch, value, color=set),
    data=glearner_long)
```

Again the plot looks reasonable, and consistent with our previous
results.

## Benchmark experiment

Is the torch linear model as accurate as the glmnet linear model?
Let's find out. First we create a grid of learners and tasks.

```{r}
(bgrid <- mlr3::benchmark_grid(
  task.list,
  list(
    glearner_auto,
    mlp_learner_auto,
    mlr3learners::LearnerClassifCVGlmnet$new(),
    mlr3::LearnerClassifFeatureless$new()),
  soak))
```

Below declare a future plan for computation in parallel on this
machine. For larger experiments you can use `mlr3batchmark` to compute
in parallel on a cluster, see my blog on the [importance of
hyper-parameter
tuning](https://tdhock.github.io/blog/2024/hyper-parameter-tuning/).

```{r}
future::plan("multisession")
```

Then we run the benchmark:

```{r}
if(file.exists("2024-10-30-mlr3torch-benchmark.rds")){
  b_result <- readRDS("2024-10-30-mlr3torch-benchmark.rds")
}else{
  b_result <- mlr3::benchmark(bgrid)
  saveRDS(b_result, "2024-10-30-mlr3torch-benchmark.rds")
}
```

## Conclusions

TODO

## Session info

```{r}
sessionInfo()
```


## MRE for issue

```{r}
N.pixels <- 10
N.classes <- 2
N.features <- 100
N.images <- 200
set.seed(1)
my.X.mat <- matrix(runif(N.features*N.images), N.images, N.features)
my.df <- data.frame(y=factor(1:N.classes), my.X.mat)
my.task <- mlr3::TaskClassif$new("MyTask", my.df, target="y")
measure_list <- mlr3::msrs(c("classif.logloss", "classif.ce", "classif.auc"))

## regular MLP with patience works.
lrn_mlp <- mlr3::lrn("classif.mlp",
  neurons = c(50, 50),
  batch_size = 256,
  epochs = 30, # Number of training epochs
  device = "auto", # Uses GPU if available, otherwise CPU
  shuffle = TRUE, # because iris is sorted
  optimizer = mlr3torch::t_opt("adamw"),
  loss = mlr3torch::t_loss("cross_entropy"))
lrn_mlp$configure(
  validate = 0.3,
  callbacks = mlr3torch::t_clbk("history"),
  predict_type = "prob",
  patience=10,
  measures_valid = measure_list,
  measures_train = measure_list)
lrn_mlp$train(my.task)
lrn_mlp$model$callbacks$history

## Regular MLP with auto-tuner works.
l = mlr3::lrn("classif.mlp",
  epochs = paradox::to_tune(upper = 100L, internal = TRUE),
  measures_train = measure_list,
  measures_valid = measure_list,
  patience = 100L,
  optimizer = mlr3torch::t_opt("adamw", lr = 0.3),
  callbacks = mlr3torch::t_clbk("history"),
  batch_size = 64,
  validate = 0.3,
  predict_type = "prob")
task = mlr3::tsk("sonar")
l$predict_sets = NULL
at = mlr3tuning::auto_tuner(
  learner = l,
  tuner = mlr3tuning::tnr("internal"),
  # the train/valid split is handled by the learner itself
  resampling = mlr3::rsmp("insample"),
  # for the optimal model we will use the internal validation score
  # computed during training
  measure = mlr3::msr("internal_valid_score", minimize = TRUE),
  # early stopping just needs a single run
  term_evals = 1,
  # so we can access the history afterwards
  store_models = TRUE)
at$train(task)

## visualize measures from auto-tuner.
pat <- function(name, ...){
  old2new <- c(...)
  nc::group(name, paste(names(old2new), collapse="|"), function(x)old2new[x])
}
measure_long <- nc::capture_melt_single(
  at$archive$learners(1)[[1L]]$model$callbacks$history,
  pat("set", train="subtrain", valid="validation"),
  ".classif.",
  pat("measure", ce="error_prop", auc="AUC", logloss="logloss"))
selected_row <- as.data.table(at$tuning_result$internal_tuned_values[[1]])
ggplot()+
  facet_grid(measure ~ ., scales="free")+
  geom_vline(aes(
    xintercept=epochs),
    data=selected_row)+
  geom_line(aes(
    epoch, value, color=set),
    data=measure_long)

## pipeops learner with patience works.
po_list_linear_ce <- list(
  mlr3pipelines::po(
    "select",
    selector = mlr3pipelines::selector_type(c("numeric", "integer"))),
  mlr3torch::PipeOpTorchIngressNumeric$new(),
  mlr3pipelines::po("nn_head"),
  mlr3pipelines::po(
    "torch_loss",
    mlr3torch::t_loss("cross_entropy")),
  mlr3pipelines::po(
    "torch_optimizer",
    mlr3torch::t_opt("adamw")),
  mlr3pipelines::po(
    "torch_callbacks",
    mlr3torch::t_clbk("history")),
  mlr3pipelines::po(
    "torch_model_classif",
    batch_size = N.images,
    patience=10,
    measures_valid=measure_list,
    measures_train=measure_list,
    predict_type="prob",
    epochs = 30))
graph_linear_ce <- Reduce(mlr3pipelines::concat_graphs, po_list_linear_ce)
glearner_linear_ce <- mlr3::as_learner(graph_linear_ce)
mlr3::set_validate(glearner_linear_ce, validate = 0.5)
glearner_linear_ce$train(my.task)
glearner_linear_ce$model$torch_model_classif$model$callbacks$history

## pipeops learner with autotuner?
po_list_linear_ce <- list(
  mlr3pipelines::po(
    "select",
    selector = mlr3pipelines::selector_type(c("numeric", "integer"))),
  mlr3torch::PipeOpTorchIngressNumeric$new(),
  mlr3pipelines::po("nn_head"),
  mlr3pipelines::po(
    "torch_loss",
    mlr3torch::t_loss("cross_entropy")),
  mlr3pipelines::po(
    "torch_optimizer",
    mlr3torch::t_opt("adamw")),
  mlr3pipelines::po(
    "torch_callbacks",
    mlr3torch::t_clbk("history")),
  mlr3pipelines::po(
    "torch_model_classif",
    batch_size = N.images,
    patience=100L,
    measures_valid=measure_list,
    measures_train=measure_list,
    predict_type="prob",
    epochs = paradox::to_tune(upper = 100L, internal = TRUE)))
graph_linear_ce <- Reduce(mlr3pipelines::concat_graphs, po_list_linear_ce)
glearner_linear_ce <- mlr3::as_learner(graph_linear_ce)
mlr3::set_validate(glearner_linear_ce, validate = 0.5)
glearner_linear_ce$predict_sets = NULL
at = mlr3tuning::auto_tuner(
  learner = glearner_linear_ce,
  tuner = mlr3tuning::tnr("internal"),
  # the train/valid split is handled by the learner itself
  resampling = mlr3::rsmp("insample"),
  # for the optimal model we will use the internal validation score
  # computed during training
  measure = mlr3::msr("internal_valid_score", minimize = TRUE),
  # early stopping just needs a single run
  term_evals = 1,
  # so we can access the history afterwards
  store_models = TRUE)
at$train(my.task)

## visualize measures from auto-tuner.
pat <- function(name, ...){
  old2new <- c(...)
  nc::group(name, paste(names(old2new), collapse="|"), function(x)old2new[x])
}
m <- at$archive$learners(1)[[1]]$model
measure_long <- nc::capture_melt_single(
  m$torch_model_classif$model$callbacks$history,
  pat("set", train="subtrain", valid="validation"),
  ".classif.",
  pat("measure", ce="error_prop", auc="AUC", logloss="logloss"))
(selected_row <- as.data.table(at$tuning_result$internal_tuned_values[[1]]))
ggplot()+
  facet_grid(measure ~ ., scales="free")+
  geom_vline(aes(
    xintercept=torch_model_classif.epochs),
    data=selected_row)+
  geom_line(aes(
    epoch, value, color=set),
    data=measure_long)

## conv
graph <- mlr3pipelines::po("select", selector = selector_type(c("numeric", "integer"))),
  mlr3pipelines::po("torch_ingress_num"),
  mlr3pipelines::po("nn_reshape", shape=c(-1,1,N.pixels,N.pixels)),
  mlr3pipelines::po("nn_conv2d_1", out_channels = 20, kernel_size = 3),
  mlr3pipelines::po("nn_relu_1", inplace = TRUE),
  mlr3pipelines::po("nn_max_pool2d_1", kernel_size = 2),
  mlr3pipelines::po("nn_flatten"),
  mlr3pipelines::po("nn_linear", out_features = 100),
  mlr3pipelines::po("nn_head"),
  mlr3pipelines::po("torch_loss", t_loss("cross_entropy")),
  mlr3pipelines::po("torch_optimizer", t_opt("sgd", lr=0.01)),
  mlr3pipelines::po("torch_model_classif", batch_size = 25, epochs = 2L)
graph$train(my.task)
graph$predict(my.task)

```

