---
layout: post
title: MPI for parallelization in R
description: Another method for machine learning experiments
---

```{r Ropts, echo=FALSE, results='hide'}
repo.dir <- normalizePath("..")
post.id <- "2025-08-14-pbdMPI"
fig.path <- paste0(file.path(repo.dir, "assets", "img", post.id), "/")
dir.create(fig.path, showWarnings = FALSE, recursive = TRUE)
knitr::opts_chunk$set(
  dpi=100,
  fig.path=fig.path,
  fig.width=10, ## TODO python figures wider? look at prev issue.
  fig.process=function(path)sub(repo.dir, "", path, fixed=TRUE),
  fig.height=4)
in_render <- !is.null(knitr::opts_knit$get('rmarkdown.pandoc.to'))
in_knit <- isTRUE(getOption('knitr.in.progress'))
options(width=120)
if(FALSE){
  knitr::knit(paste0(post.id, ".Rmd"))
}
```

The goal of this post is to show how to parallelize machine learning experiments using MPI.

## Motivation

This page is similar to [another page with an example involving parallel computation of change-point models](https://tdhock.github.io/blog/2025/rush-change-point/).

## Common code

This code defines the number of CPUs, and number of jobs to compute.

```{r}
NCPU <- 11
workers <- NCPU-1
Njob <- 100
work.id.vec <- 1:Njob
```

The code below defines a function which will be run with one job ID, in different parallel computing frameworks.

```{r}
my_sleep <- function(work.id){
  library(data.table)
  requireNamespace("pbdMPI") #load to get accurate timing for first job.
  start <- Sys.time()
  my_rank <- tryCatch({
    pbdMPI::comm.rank()
  }, error=function(e)NA_integer_)
  Sys.sleep(work.id/100)
  data.table(my_rank, work.id, start, end=Sys.time(), proc=factor(Sys.getpid()))
}
```

The function above will sleep/wait for a variable number of seconds (depending on the job ID), and then return a data table of results (including start/end time and process ID).
Be careful: if you are running this code interactively, running `my_sleep()` will load `pbdMPI`, which will edit the environment, and then the `pbdMPI` example `system()` call below will no longer work.

Below we save the sleep function and initialize a table of timings.
To visualize the results, I coded a special Positioning Method for `directlabels::geom_dl`.

```{r}
save(work.id.vec, my_sleep, file="my_sleep.RData")
timing_tables <- list()
diff_seconds <- function(...)as.numeric(difftime(..., units="s"))
polygon.mine <- function
### Make a Positioning Method that places non-overlapping speech
### polygons at the first or last points.
(top.bottom.left.right,
### Character string indicating what side of the plot to label.
  offset.cm=0.1,
### Offset from the polygon to the most extreme data point.
  padding.cm=0.05,
### Padding inside the polygon.
  custom.colors=NULL
### Positioning method applied just before draw.polygons, can set
### box.color and text.color for custom colors.
){
  if(is.null(custom.colors)){
    custom.colors <- directlabels::gapply.fun({
      rgb.mat <- col2rgb(d[["colour"]])
      d$text.color <- with(data.frame(t(rgb.mat)), {
        gray <- 0.3*red + 0.59*green + 0.11*blue
        ifelse(gray/255 < 0.5, "white", "black")
      })
      d
    })
  }
  opposite.side <- c(
    left="right",
    right="left",
    top="bottom",
    bottom="top")[[top.bottom.left.right]]
  direction <- if(
    top.bottom.left.right %in% c("bottom", "left")
  ) -1 else 1
  min.or.max <- if(
    top.bottom.left.right %in% c("top", "right")
  ) max else min
  if(top.bottom.left.right %in% c("left", "right")){
    min.or.max.xy <- "x"
    qp.target <- "y"
    qp.max <- "top"
    qp.min <- "bottom"
    padding.h.factor <- 2
    padding.w.factor <- 1
    limits.fun <- ylimits
    reduce.method <- "reduce.cex.lr"
  }else{
    min.or.max.xy <- "y"
    qp.target <- "x"
    qp.max <- "right"
    qp.min <- "left"
    padding.h.factor <- 1
    padding.w.factor <- 2
    limits.fun <- directlabels::xlimits
    reduce.method <- "reduce.cex.tb"
  }
  list(
    hjust=0.5, 
    function(d,...){
      ## set the end of the speech polygon to the original data point.
      for(xy in c("x", "y")){
        extra.coord <- sprintf(# e.g. left.x
          "%s.%s", opposite.side, xy)
        d[[extra.coord]] <- d[[xy]]
      }
      ## offset positions but do NOT set the speech polygon position
      ## to the min or max.
      d[[min.or.max.xy]] <- d[[min.or.max.xy]] + offset.cm*direction
      d
    },
    "calc.boxes",
    reduce.method,
    function(d, ...){
      d$h <- d$h + padding.cm * padding.h.factor
      d$w <- d$w + padding.cm * padding.w.factor
      d
    },
    "calc.borders",
    function(d,...){
      do.call(rbind, lapply(split(d, d$y), function(d){
        directlabels::apply.method(directlabels::qp.labels(
          qp.target,
          qp.min,
          qp.max,
          directlabels::make.tiebreaker(min.or.max.xy, qp.target),
          limits.fun), d)
      }))
    },
    "calc.borders",
    custom.colors,
    "draw.polygons")
}
my.polygons <- list(cex=0.7, vjust=0, polygon.mine(
  "top", offset.cm=0.2, custom.colors=list(box.color="white")))
make_gg <- function(package, expr){
  before <- Sys.time()
  result <- eval(expr)
  if(!is.data.table(result))result <- rbindlist(result)
  after <- Sys.time()
  DT <- data.table(before, after, result)
  timing_tables[[package]] <<- DT
  library(ggplot2)
  rect_dt <- unique(DT[, .(before, after)])
  seconds_possible <- workers*rect_dt[, diff_seconds(after, before)]
  seconds_used <- sum(DT[, diff_seconds(end, start)])
  ggplot()+
    ggtitle(sprintf("%s efficiency = %.1f%%", package, 100*seconds_used/seconds_possible))+
    theme_bw()+
    geom_rect(aes(
      xmin=before, xmax=after,
      ymin = -Inf, ymax=Inf),
      data=rect_dt,
      alpha=0.5,
      fill="grey")+
    geom_segment(aes(
      start, proc,
      xend=end, yend=proc),
      data=DT)+
    geom_point(aes(
      start, proc),
      shape=1,
      data=DT)+
    directlabels::geom_dl(aes(
      start, proc,
      label.group=paste(work.id, proc),
      label=work.id),
      data=DT,
      method=my.polygons)+
    scale_x_continuous("Time (seconds)")
}
library(data.table)
```

## `mirai` code

In R we can use the code below to ask `mirai` to do the scheduling using processes on the local computer:

```{r mirai}
mirai::daemons(NULL)
mirai::daemons(workers)
make_gg("mirai", mirai::mirai_map(work.id.vec, my_sleep)[])
```

We see in the figure above that there are 3 processes (Y axis ticks), and 10 jobs (labels and segments).

## `future` code

Another way to do it in R is using `future` package for scheduling:

```{r future}
future::plan("multisession", workers=workers)
make_gg("future", future.apply::future_lapply(work.id.vec, my_sleep))
```

The figure above shows similar trends, but with a noticeable delay between processes, and some idle time in the first process (static scheduling).

## `pbdMPI` code

Another way to do it in R is via MPI, using the `pbdMPI` package:

```{r}
cat('library(data.table)
load("my_sleep.RData")
ret_dt_list <- pbdMPI::task.pull(work.id.vec, my_sleep)
ret_dt <- rbindlist(ret_dt_list)
if(pbdMPI::comm.rank() == 0)fwrite(ret_dt, "task_pull.csv")
pbdMPI::finalize()
', file="task_pull.R")
cmd <- sprintf("mpiexec -np %d Rscript --vanilla task_pull.R", NCPU)
```

Note in the code above we have used `mpiexec` to run `Rscript` with a certain number of CPUs (`-np` argument).
In the context of a SLURM compute cluster, we can substitute `mpiexec -np 4` with `srun`, which will use MPI with `-np` set to the number of tasks in the job (`sbatch --ntasks`).
This is the approach we use in [`mlr3resampling::proj_submit()`](https://github.com/tdhock/mlr3resampling/blob/main/R/proj.R#L258).

```{r pbdMPI}
unlink("task_pull.csv")
make_gg("pbdMPI", {
  system(cmd)
  fread("task_pull.csv", colClasses=list(factor="proc"))
})
```

The figure above shows that the `pbdMPI` scheduling is more efficient than `future`, but also static (nearby jobs are assigned to different processes).

## Compare

In this section, we combine results from the different packages.

```{r compare, fig.height=8}
add_seconds <- function(DT, sec.cols = c("start","end","before","after"))DT[
, paste0(sec.cols, ".seconds") :=
    lapply(sec.cols, function(x)diff_seconds(get(x), before))
]
(compare_dt <- data.table(package=names(timing_tables))[
, add_seconds(timing_tables[[package]])
, by=package])
rect_dt <- unique(compare_dt[, .(package, before.seconds, after.seconds)])
ggplot()+
  theme_bw()+
  geom_blank(aes(
    -Inf, ""),
    data=unique(compare_dt[, .(package)]))+
  geom_rect(aes(
    xmin=before.seconds, xmax=after.seconds,
    ymin = -Inf, ymax=Inf),
    data=rect_dt,
    alpha=0.5,
    fill="grey")+
  geom_segment(aes(
    start.seconds, proc,
    xend=end.seconds, yend=proc),
    data=compare_dt)+
  geom_point(aes(
    start.seconds, proc),
    shape=1,
    data=compare_dt)+
  directlabels::geom_dl(aes(
    start.seconds, proc,
    label.group=paste(work.id, proc),
    label=work.id),
    data=compare_dt,
    method=my.polygons)+
  facet_grid(package ~ ., labeller=label_both, scales="free")+
  scale_y_discrete("process")+
  scale_x_continuous(
    "Seconds since line before apply",
    limits=c(0, NA))
```

The figure above shows a pretty substantial difference: `future` uses static scheduling (first ten jobs on first processor, etc), and so does `pbdMPI` (first ten jobs are assigned to run first on the ten CPUs, etc), and `mirai` is dynamic (each processor asks for a new job from a queue).
Although the MPI approach is slightly less efficient than `mirai` in this simple example, it is more easily usable on a SLURM cluster.
Furthermore, the MPI approach can be used to overcome the limitations of `batchtools`:

* whereas `batchtools` uses one job array task, and one CPU, per work ID,
* dynamic scheduling with MPI allows treatment of heterogeneous work (with different time requirements),
* and multiple CPUs can be used per job (which can help mitigate the max 1000 SLURM job limit imposed by Alliance Canada).

## Similar in python

See [`torc_py`](https://github.com/IBM/torc_py).

## Conclusions

We have shown how to do parallel computations in R using several frameworks: `mirai`, `future`, and MPI.
These functions can be useful for parallelizing machine learning experiments.
In practice to use MPI to launch machine learning benchmarks, I recommend using `mlr3resampling::proj_submit()`.

## Session info

```{r}
sessionInfo()
```
